{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Python Implementation of Vector Symbolic Architectures:"
      ],
      "metadata": {
        "id": "7JvBDXZfefrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounted Drive to load GardensPointWalking image set for testing\n",
        "# Image set is provided in GitHub Repo\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpBHViQ8e5Kr",
        "outputId": "0f7a5852-1f2c-47f6-efa5-fed98326367e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**seq_slam function:**\n",
        "\n",
        "seqSLAMConv function is an integral part of the SEQUENCE-SLAM algorithm, which is used for identifying similar sequences in a database of images or patterns.\n",
        "\n",
        "It takes a difference matrix—where each element represents the dissimilarity between two images—and a sequence length as inputs. The function then applies a series of convolutions across varying velocity scales to this difference matrix.\n",
        "\n",
        "These convolutions are designed to enhance the similarity of sequential image matches over isolated matches. The velocity scale adjusts the convolution filter to account for varying motion speeds in the sequences.\n",
        "\n",
        "After applying the convolutions, the function normalizes the results and combines them to produce a new difference matrix that emphasizes the strongest sequence matches."
      ],
      "metadata": {
        "id": "aobeO75LgbZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.ndimage import convolve\n",
        "\n",
        "def seqSLAMConv(DD, n):\n",
        "    v = np.arange(0.5, 1.6, 0.1)\n",
        "    T = np.zeros((DD.shape[0], DD.shape[1], len(v)))\n",
        "    supVal = 0\n",
        "    prevFilter = None\n",
        "    idx = 0\n",
        "    for i in range(len(v)):\n",
        "        H = getFilter(n, v[i])\n",
        "        if not isSame(H, prevFilter):\n",
        "            T[:,:,idx] = convolve(DD, H, mode='constant', cval=supVal)\n",
        "            W = convolve(np.ones_like(DD), H, mode='constant')\n",
        "            T[:,:,idx] /= W\n",
        "            idx += 1\n",
        "            prevFilter = H\n",
        "    T[:,:,idx:] = []\n",
        "    DDD = np.max(T, axis=2)\n",
        "    return DDD\n",
        "\n",
        "def getFilter(n, v):\n",
        "    assert v > 0\n",
        "    assert v >= 0.5\n",
        "    nh = n // 2\n",
        "    x = np.arange(1, nh+1)\n",
        "    y = np.round(x * v).astype(int)\n",
        "    hh = np.max(y)\n",
        "    wh = np.max(x)\n",
        "    idx = np.ravel_multi_index((y-1, x-1), (hh, wh))\n",
        "    Hh = np.zeros((hh, wh))\n",
        "    Hh.flat[idx] = 1\n",
        "    H = np.block([[Hh, np.zeros((hh, wh+1))],\n",
        "                  [np.zeros((1, wh)), 1, np.zeros((1, wh))],\n",
        "                  [np.zeros((hh, wh+1)), Hh]])\n",
        "    return H\n",
        "\n",
        "def isSame(X, Y):\n",
        "    return np.array_equal(X, Y)"
      ],
      "metadata": {
        "id": "93oI5wvDga42"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**get_slsbh function:**\n",
        "\n",
        "\n",
        "The get_sLSBH function is designed to generate Sparse Localized Spectral Binary Hashes (sLSBH) for a given dataset Y.\n",
        "\n",
        "The process begins by determining a threshold n based on a sparsity parameter s, which dictates the number of significant components to retain. The function first performs a random projection of the data and then sorts it to identify the top n components, thereby sparsifying the data.\n",
        "\n",
        "This operation is performed twice—once in descending order to create a hash L1 and once in ascending order to create L2. These two hashes are then concatenated to form a more robust binary hash L, which captures the essential features of the dataset while reducing its dimensionality.\n",
        "\n",
        "This binary hash can be used in various tasks such as indexing, retrieval, and classification, providing a compressed yet informative representation of the data."
      ],
      "metadata": {
        "id": "ymuqhnkogayE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_sLSBH(Y, s):\n",
        "    n = round(Y.shape[1] * s)\n",
        "    # random projection\n",
        "    Y2 = Y.copy()\n",
        "    # sort\n",
        "    IDX = np.argsort(Y2, axis=1)[:, ::-1]\n",
        "    # sparsification\n",
        "    L1 = np.zeros(Y2.shape, dtype=np.float32)\n",
        "    for i in range(Y2.shape[0]):\n",
        "        L1[i, IDX[i, :n]] = 1\n",
        "    # sort\n",
        "    IDX = np.argsort(Y2, axis=1)\n",
        "    # sparsification\n",
        "    L2 = np.zeros(Y2.shape, dtype=np.float32)\n",
        "    for i in range(Y2.shape[0]):\n",
        "        L2[i, IDX[i, :n]] = 1\n",
        "    # concat\n",
        "    L = np.concatenate((L1, L2), axis=1)\n",
        "    return L"
      ],
      "metadata": {
        "id": "gbWKrIMdgark"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**creatPR function:**\n",
        "\n",
        "\n",
        "The createPR function generates precision-recall (PR) curves for evaluating sequence matching algorithms. Given a similarity matrix S, hard ground truth GThard, and optionally a soft ground truth GTsoft, it calculates the precision and recall for different threshold values.\n",
        "\n",
        "If the removeDiagFlag is set, diagonal elements representing self-matches are removed from consideration. The singleMatchFlag ensures only the highest similarity scores are considered for each sequence, effectively enforcing a one-to-one match.\n",
        "\n",
        "The function iteratively calculates precision and recall across the range of scores in S, identifying the threshold that yields the best F1 score. Additionally, the visualizePRAtThresh helper function creates a visual representation of true positives, false negatives, and false positives at the optimal threshold, aiding in the interpretability of the results."
      ],
      "metadata": {
        "id": "OUAzj5UEgakQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "def createPR(S, GThard, GTsoft, removeDiagFlag, singleMatchFlag, evalAllSValuesFlag):\n",
        "    if not evalAllSValuesFlag:\n",
        "        evalAllSValuesFlag = 0\n",
        "    GT = np.array(GThard, dtype=bool)\n",
        "\n",
        "    if removeDiagFlag:\n",
        "        if GTsoft.size > 0:\n",
        "            seedIm = np.zeros_like(GT)\n",
        "            seedIm[0, 0] = 1\n",
        "            maindiaMask = np.logical_or(GTsoft, GTsoft.T)\n",
        "            maindiaMask = np.logical_or(maindiaMask, np.eye(GT.shape[0], dtype=bool))\n",
        "        else:\n",
        "            maindiaMask = np.eye(GT.shape[0], dtype=bool)\n",
        "\n",
        "        maindiaMask = np.logical_or(maindiaMask, np.tril(np.ones_like(S, dtype=bool)))\n",
        "        S[maindiaMask] = np.min(S)\n",
        "        GT[maindiaMask] = False\n",
        "\n",
        "    if GTsoft.size > 0:\n",
        "        S[np.logical_and(GTsoft, np.logical_not(GThard))] = np.min(S)\n",
        "\n",
        "    if singleMatchFlag:\n",
        "        hIdx = np.argmax(S, axis=0)\n",
        "        hIdxInd = np.ravel_multi_index((hIdx, np.arange(S.shape[1])), S.shape)\n",
        "        T = np.full_like(S, np.min(S))\n",
        "        T.flat[hIdxInd] = S.flat[hIdxInd]\n",
        "        S = T\n",
        "\n",
        "    R = [0]\n",
        "    P = [1]\n",
        "    startV = np.max(S)\n",
        "    endV = np.min(S)\n",
        "    bestF = 0\n",
        "    bestT = startV\n",
        "    bestP = 0\n",
        "    bestR = 0\n",
        "\n",
        "    if evalAllSValuesFlag:\n",
        "        s_vals = np.sort(np.unique(S))[::-1]\n",
        "    else:\n",
        "        s_vals = np.linspace(startV, endV, 100)\n",
        "\n",
        "    GT_sparse = csr_matrix(GT)\n",
        "\n",
        "    for i in s_vals:\n",
        "        B = S >= i\n",
        "        TP = np.count_nonzero(GT_sparse.multiply(B))\n",
        "        FN = np.count_nonzero(GT_sparse.multiply(np.logical_not(B)))\n",
        "        FP = np.count_nonzero(np.logical_not(GT) & B)\n",
        "        P.append(TP / (TP + FP))\n",
        "        R.append(TP / (TP + FN))\n",
        "        F = 2 * P[-1] * R[-1] / (P[-1] + R[-1])\n",
        "        if F > bestF:\n",
        "            bestF = F\n",
        "            bestT = i\n",
        "            bestP = P[-1]\n",
        "            bestR = R[-1]\n",
        "\n",
        "    R.append(1)\n",
        "    P.append(0)\n",
        "    V = visualizePRAtThresh(S, GT, bestT)\n",
        "\n",
        "    return P, R, V, bestP, bestR, bestF\n",
        "\n",
        "def visualizePRAtThresh(S, GT, t):\n",
        "    B = S >= t\n",
        "    TP = GT & B\n",
        "    FN = GT & np.logical_not(B)\n",
        "    FP = np.logical_not(GT) & B\n",
        "    V = np.dstack((FP, TP, FN))\n",
        "\n",
        "    return V"
      ],
      "metadata": {
        "id": "MbFRwKFzgac-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**unbind_vectors operation:**\n",
        "\n",
        "The unbind_vectors function is designed to reverse the binding operation between pairs of vectors in various Vector Symbolic Architecture (VSA) models. It takes as inputs two sets of vectors and the VSA model identifier, then performs model-specific unbinding operations. For instance, in MAP models, it executes element-wise multiplication, while for BSC, it uses an efficient XOR operation. The BSDC model requires a similarity search instead of direct unbinding. For HRR and FHRR, the function applies Fourier transform-based involution and complex arithmetic, respectively. In the BSDC_SHIFT model, it involves array shifting, and for BSDC_SEG, it handles sparse segments. The function showcases the diverse nature of unbinding across different VSA models, reflecting the need for tailored approaches to effectively reverse the binding of high-dimensional vectors."
      ],
      "metadata": {
        "id": "HhfSlJyvgaVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def unbind_vectors(vsa, vectors_1, vectors_2, **kwargs):\n",
        "    # scken, 2020\n",
        "    default_density = 1/np.sqrt(vectors_1.shape[0])  # density computing is optained from rachkovskji (most capacity and good stability)\n",
        "\n",
        "    density = kwargs.get('density', default_density)\n",
        "\n",
        "    if vsa in ['MAP_B', 'MAP_C', 'MAP_I']:\n",
        "        # elementwise multiplication\n",
        "        unbound_vectors = vectors_1 * vectors_2\n",
        "    elif vsa == 'BSC':\n",
        "        # efficient xor implementation for multi inputs\n",
        "        unbound_vectors = np.double(np.add(vectors_1, vectors_2) == 1)\n",
        "    elif vsa == 'BSDC':\n",
        "        # find the most similar item in item_mem\n",
        "        print('There is no specific unbind operator for the selected VSA - use the finding of the most similar vectors in item memory instead!')\n",
        "    elif vsa == 'BSDC_SHIFT':\n",
        "        # calculate the shift number (sum of all ones-index)\n",
        "        idx = np.arange(1, vectors_1.shape[0]+1).dot(vectors_1)\n",
        "        # shift each column with specific index number\n",
        "        unbound_vectors = np.zeros(vectors_1.shape)\n",
        "        for i in range(idx.size):\n",
        "            unbound_vectors[:, i] = np.roll(vectors_2[:, i], -idx[i])\n",
        "    elif vsa == 'HRR':\n",
        "        # involution as approximate inverse\n",
        "        inverse = np.vstack((vectors_1[0, :], np.flip(vectors_1[1:, :], axis=0)))\n",
        "        unbound_vectors = np.fft.ifft(np.fft.fft(inverse, vectors_1.shape[0], axis=0) * np.fft.fft(vectors_2, vectors_2.shape[0], axis=0), axis=0)\n",
        "    elif vsa == 'FHRR':\n",
        "        # complex multiplication with negative 'role' vector\n",
        "        unbound_vectors = np.arctan2(np.sin(vectors_2 - vectors_1), np.cos(vectors_2 - vectors_1))\n",
        "    elif vsa == 'BSDC_SEG':\n",
        "        # sparse vectors with segements\n",
        "        dim = vectors_1.shape[0]\n",
        "        num_segments = int(np.floor(dim * density))\n",
        "        num_vecs = vectors_1.shape[1]\n",
        "        size_segments = int(np.floor(dim / num_segments))\n",
        "        role = vectors_1[:num_segments*size_segments, :]\n",
        "        filler = vectors_2[:num_segments*size_segments, :]\n",
        "        # first part of the vector\n",
        "        role_segments = np.reshape(role, (size_segments, num_segments, num_vecs))\n",
        "        filler_segments = np.reshape(filler, (size_segments, num_segments, num_vecs))\n",
        "        role_idx = np.where(role_segments)\n",
        "        filler_idx = np.where(filler_segments)\n",
        "        role_rows, role_cols, role_tables = np.unravel_index(role_idx, role_segments.shape)\n",
        "        filler_rows, filler_cols, filler_tables = np.unravel_index(filler_idx, filler_segments.shape)\n",
        "        result_rows = np.mod(filler_rows - role_rows[filler_cols*filler_tables] - 1, size_segments) + 1\n",
        "        unbound_vectors = np.zeros(role_segments.shape)\n",
        "        idx = np.ravel_multi_index((result_rows, filler_cols, filler_tables), role_segments.shape)\n",
        "        unbound_vectors.flat[idx] = 1\n",
        "        unbound_vectors = np.reshape(unbound_vectors, (size_segments*num_segments, num_vecs))\n",
        "        # if there is a remain part\n",
        "        unbound_vectors_part2 = np.empty((0, num_vecs))\n",
        "        if num_segments*size_segments != dim:\n",
        "            filler = vectors_2[num_segments*size_segments:, :]\n",
        "            unbound_vectors_part2 = filler\n",
        "        unbound_vectors = np.vstack((unbound_vectors, unbound_vectors_part2))\n",
        "    else:\n",
        "        print('Representation is not defined!')\n",
        "\n",
        "    return unbound_vectors"
      ],
      "metadata": {
        "id": "TOEL3fcugaNF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**get_ngram operation:**\n",
        "\n",
        "\n",
        "The getNgram function constructs n-grams using a specified Vector Symbolic Architecture (VSA) model. An n-gram is a contiguous sequence of n items from a given sequence of text or speech. This function translates a sequence of keys into their corresponding character codes, then iteratively binds and permutes character vectors from an item memory to form the n-gram representation. It demonstrates how sequences, such as words or phrases, can be encoded into the high-dimensional vector space characteristic of VSAs, preserving the sequential nature of the input through the VSA's binding and permutation operations."
      ],
      "metadata": {
        "id": "V5vSFBZqgZb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getNgram(VSA, keys, char_item_memory, seq_item_memory):\n",
        "    key_codes = [ord(key) for key in keys]\n",
        "    num_ngrams = len(key_codes)\n",
        "    # create ngrams\n",
        "    ngram = VSA.permute(char_item_memory[:, key_codes[0]])\n",
        "    for i in range(1, num_ngrams):\n",
        "        ngram = VSA.bind(ngram, VSA.permute(char_item_memory[:, key_codes[i]], i))\n",
        "    return ngram"
      ],
      "metadata": {
        "id": "_R88qt7qgZRb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**generate_vectors operation:**\n",
        "\n",
        "\n",
        "The generate_vectors function is a versatile tool for generating high-dimensional vectors according to different Vector Symbolic Architectures (VSAs). Depending on the VSA specified, it can produce dense or sparse binary vectors, continuous uniform or normal distributions, or even complex-valued vectors.\n",
        "\n",
        "This function allows for the customization of the vector dimensionality, density of non-zero elements in sparse representations, and the number of vectors to generate. It's particularly useful for creating the foundational vector space for various VSA operations, such as binding, bundling, and unbinding, which are essential in cognitive computing tasks. Whether for binary sparse coding, holographic reduced representations, or Fourier holographic representations, this function provides the necessary building blocks for VSA-based computations."
      ],
      "metadata": {
        "id": "Otm57KsCgZJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_vectors(dim=10000, vsa='map', num=1, density=-1):\n",
        "    default_dim = 10000\n",
        "    default_vsa = 'map'\n",
        "    default_density = -1\n",
        "    default_num = 1\n",
        "\n",
        "    if dim is None:\n",
        "        dim = default_dim\n",
        "    if vsa is None:\n",
        "        vsa = default_vsa\n",
        "    if num is None:\n",
        "        num = default_num\n",
        "    if density is None:\n",
        "        density = default_density\n",
        "\n",
        "    if density == -1:\n",
        "        if vsa in ['BSDC', 'BSDC_test', 'BSDC_SHIFT', 'BSDC_THIN']:\n",
        "            density = 1/np.sqrt(dim)\n",
        "        elif vsa == 'BSDC_25':\n",
        "            density = 0.25\n",
        "        elif vsa == 'BSDC_SEG':\n",
        "            density = 1/np.sqrt(dim)\n",
        "        else:\n",
        "            density = 0.5\n",
        "\n",
        "    if vsa in ['MAP_B', 'MAP_I']:\n",
        "        gen_vecs = np.random.choice([-1, 1], size=(dim, num))\n",
        "    elif vsa == 'MAP_C':\n",
        "        gen_vecs = np.random.uniform(low=-1, high=1, size=(dim, num))\n",
        "    elif vsa == 'BSC':\n",
        "        gen_vecs = np.random.choice([0, 1], size=(dim, num))\n",
        "    elif vsa in ['BSDC', 'BSDC_SHIFT', 'BSDC_25', 'BSDC_THIN']:\n",
        "        rand_values = np.random.uniform(low=0, high=1, size=(dim, num))\n",
        "        rows = np.argpartition(rand_values, -int(dim*density), axis=0)[-int(dim*density):]\n",
        "        values = np.zeros_like(rand_values)\n",
        "        values[rows, np.arange(num)] = 1\n",
        "        gen_vecs = values\n",
        "    elif vsa == 'BSDC_SEG':\n",
        "        num_segments = int(dim*density)\n",
        "        size_segments = int(dim/num_segments)\n",
        "        z = np.zeros((size_segments, num_segments, num))\n",
        "        rand_r = np.random.randint(low=0, high=size_segments, size=(num_segments, num))\n",
        "        rand_c = np.repeat(np.arange(num_segments)[:, np.newaxis], num, axis=1)\n",
        "        rand_t = np.repeat(np.arange(num)[np.newaxis, :], num_segments, axis=0)\n",
        "        indices = np.stack((rand_r, rand_c, rand_t), axis=-1)\n",
        "        z[tuple(indices.T)] = 1\n",
        "        gen_vecs = z.reshape(-1, num)\n",
        "        if dim != num_segments*size_segments:\n",
        "            d = dim - num_segments*size_segments\n",
        "            gen_vecs = np.concatenate((gen_vecs, np.zeros((d, num))), axis=0)\n",
        "    elif vsa in ['HRR', 'HRR_VTB', 'MBAT']:\n",
        "        gen_vecs = np.random.normal(loc=0, scale=np.sqrt(1/dim), size=(dim, num))\n",
        "    elif vsa in ['FHRR', 'FHRR_fft', 'FHRR_cos']:\n",
        "        gen_vecs = np.random.uniform(low=-np.pi, high=np.pi, size=(dim, num))\n",
        "    else:\n",
        "        print('Representation is not defined!')\n",
        "\n",
        "    return gen_vecs"
      ],
      "metadata": {
        "id": "CFvFWYrogY82"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**fractional_bindings operation:**\n",
        "\n",
        "The fractional_binding function implements fractional binding operations in various Vector Symbolic Architecture (VSA) models. Fractional binding is a technique to partially bind vectors together, allowing for more nuanced and flexible representations.\n",
        "\n",
        "For models like FHRR (Fourier Holographic Reduced Representations), it performs modulo arithmetic on the vector elements, effectively scaling them by a factor k.\n",
        "\n",
        "In BSDC-based models (Binary Sparse Distributed Codes) and BSC (Binary Spatter Codes), the function utilizes the Fast Fourier Transform (FFT) to raise the vectors to the power of k and then retrieves the binary representation.\n",
        "\n",
        "This function demonstrates a key aspect of VSA - the ability to modify the traditional binding operation to capture varying degrees of association between vectors, which is vital for complex cognitive tasks."
      ],
      "metadata": {
        "id": "vJK7cOrsgY1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def fractional_binding(vsa, vector, k):\n",
        "    if vsa == 'FHRR' or vsa == 'FHRR_fft':\n",
        "        v = np.remainder(np.tile(vector, np.shape(k)) * k, np.pi)\n",
        "    elif vsa == 'BSDC' or vsa == 'BSDC_SEG' or vsa == 'BSDC_SHIFT' or vsa == 'BSC' or vsa == 'BSDC_25':\n",
        "        values = np.fft.ifft(np.fft.fft(np.tile(vector, (1, len(k))), vector.shape[0], 1) ** k, vector.shape[0], 1)\n",
        "        v = np.angle(values) > 0\n",
        "    else:\n",
        "        values = np.fft.ifft(np.fft.fft(np.tile(vector, (1, len(k))), vector.shape[0], 1) ** k, vector.shape[0], 1)\n",
        "        v = np.real(values)\n",
        "\n",
        "    return v"
      ],
      "metadata": {
        "id": "7jgE1n4VgYq5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**convert_vectors operation:**\n",
        "\n",
        "The convert_vectors function is a key component in Vector Symbolic Architectures (VSAs) that adapts input vectors to suit various VSA models. This function takes an input matrix Y and a specified VSA type, then processes and converts the vectors to conform to the representation requirements of the chosen VSA.\n",
        "\n",
        "For instance, in continuous VSAs like MAP_C, it clamps the values within a specific range, while in binary VSAs like BSC, it converts the values to binary form. The function also handles models like FHRR (Fourier Holographic Reduced Representations) by transforming vectors into their angular representation.\n",
        "\n",
        "Additionally, for sparse binary models like BSDC, it performs sparsification based on a specified density parameter. This conversion step is crucial for ensuring that the input data is compatible with the specific operations and characteristics of the chosen VSA model."
      ],
      "metadata": {
        "id": "wyDqDmy9gYiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "def convert_vectors(vsa, Y, density=None):\n",
        "    if density is None:\n",
        "        # set default density\n",
        "        if vsa in ['BSDC', 'BSDC_test', 'BSDC_SHIFT']:\n",
        "            density = 1/np.sqrt(Y.shape[1])  # density computing is optains from rachkovskji (most capacity and good stability)\n",
        "        elif vsa == 'BSDC_25':\n",
        "            density = 0.25\n",
        "        elif vsa == 'BSDC_SEG':\n",
        "            density = 1/np.sqrt(Y.shape[1])\n",
        "        else:\n",
        "            density = 0.5\n",
        "\n",
        "    if vsa == 'MAP_C':\n",
        "        # convert\n",
        "        values = Y\n",
        "        values[values > 1] = 1\n",
        "        values[values < -1] = -1\n",
        "    elif vsa == 'map_trans_uniform':\n",
        "        # convert\n",
        "        values = Y\n",
        "        for i in range(Y.shape[0]):\n",
        "            pd = norm(loc=np.mean(Y[i,:]), scale=np.sqrt(np.var(Y[i,:])))\n",
        "            values[i,:] = pd.cdf(Y[i,:]) * 2 - 1\n",
        "    elif vsa in ['MAP_B', 'MAP_I']:\n",
        "        # convert\n",
        "        values = np.double(Y > 0) * 2 - 1\n",
        "    elif vsa == 'BSC':\n",
        "        # convert\n",
        "        values = np.double(Y > 0)\n",
        "    elif vsa in ['HRR', 'HRR_VTB', 'MBAT']:\n",
        "        # convert\n",
        "        values = np.linalg.norm(Y, axis=1)\n",
        "    elif vsa == 'FHRR':\n",
        "        # convert\n",
        "        values = np.angle(np.fft.fft(Y, Y.shape[1], axis=1))\n",
        "    elif vsa in ['BSDC', 'BSDC_SHIFT', 'BSDC_SEG']:\n",
        "        # project values\n",
        "        values = get_sLSBH(Y, density)\n",
        "    elif vsa in ['NONE', 'Proj.']:\n",
        "        # use the original vectors without converting\n",
        "        values = Y\n",
        "    else:\n",
        "        print('Representation is not defined!')\n",
        "\n",
        "    return values"
      ],
      "metadata": {
        "id": "DT8egMrOgYYq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**compute_sim operation:**\n",
        "\n",
        "The compute_sim function is a versatile utility for calculating similarity between two sets of vectors using various similarity metrics, depending on the specified VSA (Vector Symbolic Architecture) type. It takes two sets of vectors, vectors_1 and vectors_2, and computes a similarity matrix between them.\n",
        "\n",
        "The similarity calculation method varies based on the chosen VSA type:\n",
        "\n",
        "- Cosine Similarity (MAP_B, MAP_C, HRR, HRR_VTB, NONE, MAP_I, MBAT, Proj,\n",
        "\n",
        "- FHRR_cos): For continuous VSAs (MAP_C, HRR), it calculates the cosine similarity between vectors. For binary VSAs (MAP_B, MAP_I), it uses a modified cosine similarity. For complex-valued VSAs (MBAT, FHRR_cos), it computes the average cosine of the angle between vectors.\n",
        "\n",
        "- Hamming Distance (BSC): For binary sparse coding (BSC), it computes the Hamming distance between binary vectors.\n",
        "\n",
        "- Overlap (BSDC, BSDC_SHIFT, BSDC_25, BSDC_SEG, BSDC_THIN): For various forms of binary sparse distributed representations (BSDC), it calculates the overlap between binary vectors.\n",
        "Average Cosine of Distance (FHRR_fft, FHRR):\n",
        "\n",
        "- For Fourier-based Holographic Reduced Representations (FHRR), it computes the average cosine of the distance between complex-valued vectors.\n",
        "\n",
        "The function first transposes the input arrays to ensure proper alignment for the similarity calculations. It then initializes a similarity matrix and proceeds to calculate the similarity values based on the selected VSA type. The choice of VSA determines which mathematical operation is performed to measure similarity. This function is essential for assessing the similarity between vectors, which is a fundamental operation in many VSA applications."
      ],
      "metadata": {
        "id": "f9pEPvjRgYOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_sim(vsa, vectors_1, vectors_2):\n",
        "    # first transpose the arrays\n",
        "    vectors_1 = vectors_1.T\n",
        "    vectors_2 = vectors_2.T\n",
        "    sim_matrix = np.zeros((vectors_1.shape[0], vectors_2.shape[0]))\n",
        "    np.warnings.filterwarnings('ignore')\n",
        "    if vsa in ['MAP_B', 'MAP_C', 'HRR', 'HRR_VTB', 'NONE', 'MAP_I', 'MBAT', 'Proj', 'FHRR_cos']:\n",
        "        # cosine similarity\n",
        "        sim_matrix = (vectors_1 / np.sqrt(np.sum(vectors_1**2, axis=1, keepdims=True))) @ (vectors_2 / np.sqrt(np.sum(vectors_2**2, axis=1, keepdims=True))).T\n",
        "    elif vsa == 'BSC':\n",
        "        # hamming distance\n",
        "        sim_matrix = 1 - pdist2(vectors_1, vectors_2, metric='hamming')\n",
        "    elif vsa in ['BSDC', 'BSDC_SHIFT', 'BSDC_25', 'BSDC_SEG', 'BSDC_THIN']:\n",
        "        # overlap\n",
        "        vectors_1 = vectors_1 > 0\n",
        "        vectors_2 = vectors_2 > 0\n",
        "        sim_matrix = vectors_1 @ vectors_2.T\n",
        "    elif vsa in ['FHRR_fft', 'FHRR']:\n",
        "        # average of cosine of distance\n",
        "        # convert to complex values\n",
        "        sim_matrix = np.real(np.exp(vectors_1*1j) @ np.exp(vectors_2*1j).T) / vectors_1.shape[1]\n",
        "    else:\n",
        "        print('Representation is not defined!')\n",
        "    np.warnings.filterwarnings('default')\n",
        "    return sim_matrix"
      ],
      "metadata": {
        "id": "gJBvqu9igYDj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**complex_sim operation:**\n",
        "\n",
        "\n",
        "The complexSim function calculates the similarity between two sets of complex-valued vectors, typically used in the context of Fourier-based Holographic Reduced Representations (FHRR). It computes the similarity by measuring the cosine of the angle between pairs of complex numbers in the vectors. The resulting similarity matrix indicates how similar the corresponding pairs of vectors are, with higher values indicating greater similarity."
      ],
      "metadata": {
        "id": "g6QMN6BXgX5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def complexSim(v1, v2):\n",
        "    # compute the similarity between vectors of angles (from complex numbers --> FHRR)\n",
        "    sim_matrix = np.zeros((len(v1), len(v2)))\n",
        "    for i in range(len(v1)):\n",
        "        sim_matrix[i] = np.sum(np.cos(v1[i] - v2), axis=1) / len(v1[i])\n",
        "    return sim_matrix"
      ],
      "metadata": {
        "id": "JR-LCz5TgXk1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**cdt operation:**\n",
        "\n",
        "The cdt function performs a Convolutive Displacement Transformation (CDT) operation on a superposition vector. This operation aims to reduce the density of activated elements in the superposition vector. It iteratively shifts the vector, performs element-wise logical AND with the original vector, and sets elements to zero based on certain criteria. This process continues until the mean density of activated elements across columns falls below a specified threshold (density) or until a maximum number of iterations (max_iters) is reached. The result is a modified superposition vector with reduced density, which can be useful for various operations in vector symbolic architectures."
      ],
      "metadata": {
        "id": "rX1yBXb9jXBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cdt(superposition_vector, max_iters, density):\n",
        "    Z = superposition_vector\n",
        "    counter = 1\n",
        "    while np.mean(np.sum(Z, axis=0) / Z.shape[0]) > density:\n",
        "        r = counter  # determine the shifting\n",
        "        r = counter  # determine the shifting\n",
        "        permutation = np.roll(superposition_vector, r)\n",
        "        thinned = np.logical_and(superposition_vector, permutation)\n",
        "        Z[thinned] = 0\n",
        "\n",
        "        if counter > max_iters:  # if more than max_iters iterations, break loop\n",
        "            break\n",
        "\n",
        "        counter += 1\n",
        "\n",
        "    return Z"
      ],
      "metadata": {
        "id": "DsMJuKFTjWTp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**bundle_vectors operation:**\n",
        "\n",
        "The bundle_vectors function combines two sets of vectors (vectors_1 and vectors_2) into a bundled vector representation based on a specified Vector Symbolic Architecture (VSA) method (vsa). It offers various methods for bundling vectors:\n",
        "\n",
        "- For methods like 'MAP_B', 'MAP_C', 'MAP_I', and 'BSC', it combines vectors based on majority rules, sum, or hamming distance, with optional normalization and density control.\n",
        "\n",
        "- 'BSDC' performs element-wise disjunction with optional normalization and density control.\n",
        "\n",
        "- 'HRR', 'HRR_VTB', and 'MBAT' methods add vectors element-wise, optionally normalizing them.\n",
        "\n",
        "- 'FHRR' computes the average angle between vectors.\n",
        "\n",
        "- 'BSDC_SHIFT' performs element-wise disjunction with a density-based selection of elements.\n",
        "\n",
        "- 'BSDC_SEG' bundles vectors in segments with optional normalization and density control.\n",
        "\n",
        "The resulting bundled vector representation is returned, which can be used in various vector symbolic operations."
      ],
      "metadata": {
        "id": "mqdICcb0jWNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def bundle_vectors(vsa, vectors_1, vectors_2, normalize=True, density=0.5, max_density=1):\n",
        "    # concatenate the two input vectors\n",
        "    vector_array = np.concatenate((vectors_1, vectors_2), axis=1)\n",
        "    dim = vector_array.shape[0]\n",
        "    n_dim = vectors_1.ndim\n",
        "\n",
        "    if vsa == 'MAP_B':\n",
        "        # majority rule\n",
        "        values = np.sum(vector_array, axis=n_dim)\n",
        "        if normalize:\n",
        "            values[values < -1] = -1\n",
        "            values[values > 1] = 1\n",
        "            random_choice = np.random.choice([-1, 1], size=(dim, 1))\n",
        "            values[values == 0] = random_choice[values == 0]\n",
        "        bundled_vectors = values\n",
        "    elif vsa == 'MAP_C':\n",
        "        values = np.sum(vector_array, axis=n_dim)\n",
        "        if normalize:\n",
        "            # normalization of bundled vectors\n",
        "            values[values > 1] = 1\n",
        "            values[values < -1] = -1\n",
        "        bundled_vectors = values\n",
        "    elif vsa == 'MAP_I':\n",
        "        # sum\n",
        "        bundled_vectors = np.sum(vector_array, axis=n_dim)\n",
        "    elif vsa == 'BSC':\n",
        "        values = np.sum(vector_array, axis=n_dim)\n",
        "        if normalize:\n",
        "            # check if number of vectors is odd (apply majority rule)\n",
        "            number_vec = vector_array.shape[1]\n",
        "            if number_vec % 2 == 0:\n",
        "                random_choice = np.random.choice([0, 1], size=(dim, 1))\n",
        "                values = values + random_choice\n",
        "                number_vec = number_vec + 1\n",
        "            thresh = number_vec / 2\n",
        "            # if threshold highly differ from mean, than use mean\n",
        "            # as threshold\n",
        "            if abs(thresh - np.mean(values)) > 2:\n",
        "                thresh = np.mean(values)\n",
        "            values = np.array(values > thresh, dtype=int)\n",
        "        bundled_vectors = values\n",
        "    elif vsa == 'BSDC':\n",
        "        # elementwise disjunction\n",
        "        # if normalize true, thinning of the resulting bundle\n",
        "        k = int(max_density * vector_array.shape[0])\n",
        "        values = np.sum(vector_array, axis=n_dim)\n",
        "        if normalize:\n",
        "            bundled_vectors = np.zeros((vector_array.shape[0], 1))\n",
        "            idx = np.argpartition(values, -k)[-k:]\n",
        "            bundled_vectors[idx] = values[idx] > 0\n",
        "        else:\n",
        "            bundled_vectors = np.array(values >= 1, dtype=int)\n",
        "    elif vsa in ['HRR', 'HRR_VTB', 'MBAT']:\n",
        "        # elementwise addition\n",
        "        values = np.sum(vector_array, axis=n_dim)\n",
        "        if normalize:\n",
        "            values = values / np.linalg.norm(values)\n",
        "        bundled_vectors = values\n",
        "    elif vsa == 'FHRR':\n",
        "        # average angle\n",
        "        vectors = np.concatenate((vectors_1, vectors_2), axis=1)\n",
        "        vcos = np.cos(vectors)\n",
        "        vsin = np.sin(vectors)\n",
        "        vcos_sum = np.sum(vcos, axis=n_dim)\n",
        "        vsin_sum = np.sum(vsin, axis=n_dim)\n",
        "        if normalize:\n",
        "            values = np.arctan2(vsin_sum, vcos_sum)\n",
        "        else:\n",
        "            values = vcos + 1j * vsin\n",
        "        bundled_vectors = values\n",
        "    elif vsa == 'BSDC_SHIFT':\n",
        "        # elementwise disjunction\n",
        "        # select the k highest values (k is computed with the density)\n",
        "        k = int(max_density * vector_array.shape[0])\n",
        "        values = np.sum(vector_array, axis=n_dim)\n",
        "        if normalize:\n",
        "            bundled_vectors = np.zeros((vector_array.shape[0], 1))\n",
        "            idx = np.argpartition(values, -k)[-k:]\n",
        "            bundled_vectors[idx] = values[idx] > 0\n",
        "        else:\n",
        "            bundled_vectors = np.array(values > 0, dtype=int)\n",
        "    elif vsa == 'BSDC_SEG':\n",
        "        num_segments = int(dim * density)\n",
        "        size_segments = int(dim / num_segments)\n",
        "        k = int(max_density * size_segments)\n",
        "        values = np.sum(vector_array, axis=n_dim)\n",
        "        if normalize:\n",
        "            values_segments = values[:size_segments * num_segments].reshape((size_segments, num_segments))\n",
        "            idx = np.argpartition(values_segments, -k, axis=0)[-k:]\n",
        "            idx = np.ravel_multi_index((idx, np.arange(num_segments)), values_segments.shape)\n",
        "            bundled_vectors = np.zeros(values_segments.shape)\n",
        "            bundled_vectors.ravel()[idx] = values_segments.ravel()[idx]\n",
        "            bundled_vectors = np.ravel(bundled_vectors) > 0\n",
        "        else:\n",
        "            bundled_vectors = values\n",
        "        if size_segments * num_segments != values.shape[0]:\n",
        "            bundled_vectors = np.concatenate((bundled_vectors, values[size_segments * num_segments:]))\n",
        "    else:\n",
        "        print('Representation is not defined!')\n",
        "\n",
        "    bundled_vectors = bundled_vectors.astype(float)\n",
        "    return bundled_vectors"
      ],
      "metadata": {
        "id": "yq2lYAJ0jWGn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**bind_vectors operation:**\n",
        "\n",
        "The bind_vectors function performs vector binding operations based on the specified Vector Symbolic Architecture (VSA) method (vsa). It combines two sets of vectors (vectors_1 and vectors_2) into a single bound vector representation. Here's a brief description of what it does for each method:\n",
        "\n",
        "- For 'MAP_B', 'MAP_C', and 'MAP_I', it performs element-wise multiplication between the vectors.\n",
        "\n",
        "- 'BSC' efficiently computes XOR operations between vectors.\n",
        "\n",
        "- 'BSDC' combines vectors using the CDT (Conscious Dynamic Thinning) algorithm, which involves iterative thinning to control density.\n",
        "\n",
        "- 'BSDC_SHIFT' calculates the shift number based on the dot product with a range of values and then shifts the columns of the second set of vectors accordingly.\n",
        "\n",
        "- 'HRR' uses circular convolution to bind vectors.\n",
        "\n",
        "- 'FHRR' computes the binding by taking the modulus of the sum of angles.\n",
        "\n",
        "- 'BSDC_SEG' binds vectors in segments, where each segment is bound independently.\n",
        "\n",
        "The resulting bound vector representation is returned for further use in vector symbolic operations."
      ],
      "metadata": {
        "id": "POXrjAeojV_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def bind_vectors(vsa, vectors_1, vectors_2, **kwargs):\n",
        "    default_density = 1/np.sqrt(vectors_1.shape[0])\n",
        "    density = kwargs.get('density', default_density)\n",
        "\n",
        "    bound_vectors = None\n",
        "\n",
        "    if vsa in ['MAP_B', 'MAP_C', 'MAP_I']:\n",
        "        bound_vectors = vectors_1 * vectors_2\n",
        "    elif vsa == 'BSC':\n",
        "        bound_vectors = np.double(np.add(vectors_1, vectors_2) == 1)\n",
        "    elif vsa == 'BSDC':\n",
        "        values_disj = np.double(np.add(vectors_1, vectors_2))\n",
        "        bound_vectors = cdt(values_disj, 50, 1/np.sqrt(vectors_1.shape[0]))\n",
        "    elif vsa == 'BSDC_SHIFT':\n",
        "        idx = np.arange(1, vectors_1.shape[0]+1).dot(vectors_1)\n",
        "        bound_vectors = np.zeros(vectors_1.shape)\n",
        "        for i in range(idx.size):\n",
        "            bound_vectors[:, i] = np.roll(vectors_2[:, i], idx[i])\n",
        "    elif vsa == 'HRR':\n",
        "        ccirc = np.fft.ifft(np.fft.fft(vectors_1, vectors_1.shape[0], axis=0) * np.fft.fft(vectors_2, vectors_2.shape[0], axis=0), axis=0)\n",
        "        bound_vectors = ccirc\n",
        "    elif vsa == 'FHRR':\n",
        "        bound_vectors = np.mod(vectors_1 + vectors_2 + np.pi, 2 * np.pi) - np.pi\n",
        "    elif vsa == 'BSDC_SEG':\n",
        "        dim = vectors_1.shape[0]\n",
        "        num_segments = int(np.floor(dim * density))\n",
        "        size_segments = int(np.floor(dim / num_segments))\n",
        "        num_vecs = vectors_1.shape[1]\n",
        "\n",
        "        role = vectors_1[:num_segments * size_segments, :]\n",
        "        filler = vectors_2[:num_segments * size_segments, :]\n",
        "\n",
        "        # Reshape vectors\n",
        "        role_segments = np.reshape(role, (size_segments, num_segments, num_vecs), order='F')\n",
        "        filler_segments = np.reshape(filler, (size_segments, num_segments, num_vecs), order='F')\n",
        "\n",
        "        # Find indices\n",
        "        role_idx = np.flatnonzero(role_segments)\n",
        "        filler_idx = np.flatnonzero(filler_segments)\n",
        "\n",
        "        # Convert indices to subscripts\n",
        "        role_rows, _, _ = np.unravel_index(role_idx, role_segments.shape)\n",
        "        filler_rows, filler_cols, filler_tables = np.unravel_index(filler_idx, filler_segments.shape)\n",
        "\n",
        "        # Calculate result rows\n",
        "        result_rows = np.mod(role_rows[filler_cols * filler_tables] + filler_rows - 1, size_segments) + 1\n",
        "\n",
        "        # Initialize bound_vectors\n",
        "        bound_vectors = np.zeros_like(role_segments)\n",
        "\n",
        "        # Convert subscripts back to indices and set values in bound_vectors\n",
        "        idx = np.ravel_multi_index((result_rows, filler_cols, filler_tables), role_segments.shape)\n",
        "        bound_vectors.flat[idx] = 1\n",
        "\n",
        "        # Reshape bound_vectors\n",
        "        bound_vectors = np.reshape(bound_vectors, (size_segments * num_segments, num_vecs), order='F')\n",
        "    else:\n",
        "        print('Representation is not defined!')\n",
        "\n",
        "    return bound_vectors"
      ],
      "metadata": {
        "id": "92PsZKUkjV3y"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random,string\n",
        "def generate_random_string(size):\n",
        "        return ''.join(random.choice(string.ascii_letters + string.digits))"
      ],
      "metadata": {
        "id": "Tn_SyXhw9mkq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**vsa_env operation:**\n",
        "\n",
        "The vsa_env class is a Python class that provides various Vector Symbolic Architecture (VSA) operations, and it can be used to work with different VSA implementations. Here's an overview of its key methods and functionalities:\n",
        "\n",
        "- __init__: Initializes the VSA environment with specified parameters such as VSA type (vsa), dimension (dim), density (density), and maximum density (max_density).\n",
        "\n",
        "- add_vector: Adds vectors to the environment. It generates random vectors if vec is not provided. Vectors can be associated with names for easy retrieval.\n",
        "\n",
        "- sim: Computes similarity between two sets of vectors using different similarity metrics based on the selected VSA type.\n",
        "\n",
        "- bind: Binds two sets of vectors together using the specified VSA type.\n",
        "\n",
        "- unbind: Unbinds two sets of vectors using the specified VSA type.\n",
        "\n",
        "- bundle: Bundles two sets of vectors together, with options for normalization and density control.\n",
        "\n",
        "- permute: Performs vector permutation by rolling the elements of a vector.\n",
        "\n",
        "- find_k_nearest: Finds the k-nearest vectors in the environment based on similarity.\n",
        "\n",
        "- find_by_name: Retrieves vectors by their associated names.\n",
        "\n",
        "- frac_binding: Performs fractional binding on a vector.\n",
        "\n",
        "- convert: Converts vectors using the selected VSA type.\n",
        "\n",
        "- generate_vectors: Generates random vectors based on the specified VSA type and parameters.\n",
        "\n",
        "- compute_sim: Computes similarity between two sets of vectors using different similarity metrics.\n",
        "\n",
        "- bind_vectors: Binds two sets of vectors together using the specified VSA type and density.\n",
        "\n",
        "- unbind_vectors: Unbinds two sets of vectors using the specified VSA type and density.\n",
        "\n",
        "- bundle_vectors: Bundles two sets of vectors together, with options for normalization and density control.\n",
        "\n",
        "- fractional_binding: Performs fractional binding on a vector.\n",
        "\n",
        "- convert_vectors: Converts vectors using the selected VSA type and density.\n",
        "\n",
        "This class supports various VSA implementations and perform operations like binding, unbinding, and similarity computations on sets of vectors."
      ],
      "metadata": {
        "id": "l2crXm4omQrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python class of different VSA implementation\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import hamming\n",
        "\n",
        "class vsa_env:\n",
        "    def __init__(self, vsa='MAP_B', dim=10000, density=-1, max_density=1):\n",
        "        self.dim = dim\n",
        "        self.vsa = vsa\n",
        "        self.item_mem = [[], []]\n",
        "        self.max_density = max_density\n",
        "        if density == -1:\n",
        "            if vsa in ['BSDC', 'BSDC_SHIFT']:\n",
        "                density = 1 / np.sqrt(dim)\n",
        "            elif vsa == 'BSDC_25':\n",
        "                density = 0.25\n",
        "            elif vsa == 'BSDC_SEG':\n",
        "                density = 1 / np.sqrt(dim)\n",
        "            else:\n",
        "                density = 0.5\n",
        "        self.density = density\n",
        "\n",
        "\n",
        "    def add_vector(self, vec=None, name=-1, num=1, add_item=1, return_vector=1):\n",
        "        if vec is None:\n",
        "            vectors = self.generate_vectors(self.vsa, self.dim, num, self.density)\n",
        "        else:\n",
        "            vectors = vec\n",
        "            self.item_mem[0] =  vectors\n",
        "            num = vectors.shape[1]\n",
        "\n",
        "        if add_item:\n",
        "            self.item_mem[0] =  vectors\n",
        "\n",
        "            if isinstance(name, int):\n",
        "                rand_names = self.rnd_name(size=(8,num))\n",
        "                self.item_mem[1]= rand_names\n",
        "            else:\n",
        "                names = self.item_mem[1]\n",
        "                self.item_mem[1] = np.concatenate((names, [name]))\n",
        "        if not return_vector:\n",
        "            vectors = None\n",
        "\n",
        "        return vectors\n",
        "\n",
        "    def sim(self, vectors_1, vectors_2):\n",
        "        return self.compute_sim(self.vsa, vectors_1, vectors_2)\n",
        "\n",
        "    def bind(self, vectors_1, vectors_2):\n",
        "        return self.bind_vectors(self.vsa, vectors_1, vectors_2, density=self.density)\n",
        "\n",
        "    def unbind(self, vectors_1, vectors_2):\n",
        "        return self.unbind_vectors(self.vsa, vectors_1, vectors_2, density=self.density)\n",
        "\n",
        "    def bundle(self, vectors_1, vectors_2, normalize=None):\n",
        "        if normalize is None:\n",
        "            return self.bundle_vectors(self.vsa, vectors_1, vectors_2, density=self.density, max_density=self.max_density)\n",
        "        else:\n",
        "            return self.bundle_vectors(self.vsa, vectors_1, vectors_2, normalize=normalize, density=self.density, max_density=self.max_density)\n",
        "\n",
        "    def permute(self, vector, p=1):\n",
        "        return np.roll(vector, p)\n",
        "\n",
        "    def find_k_nearest(self,vectors_in, k=1):\n",
        "        sim_vec = self.sim(self.item_mem[0], vectors_in)\n",
        "        idx = np.argsort(sim_vec)[::-1]\n",
        "        sim_vec_sort = sim_vec[idx]\n",
        "        s_highest = sim_vec_sort[:k]\n",
        "        rows = idx[:k]\n",
        "        names = self.item_mem[1]\n",
        "\n",
        "        names = names[rows]\n",
        "        #names = names.reshape((k, vectors_in.shape[1]))\n",
        "        vecs = self.item_mem[0]\n",
        "        vectors = vecs[:, rows]\n",
        "        #vectors = vectors.reshape((vectors.shape[0], k, vectors_in.shape[1]))\n",
        "        s = sim_vec[:k,:]\n",
        "        s = s.reshape((k, vectors_in.shape[1]))\n",
        "\n",
        "        return vecs, names, s\n",
        "\n",
        "    def find_by_name(self, vector_name):\n",
        "        idx = np.where(self.item_mem[1] == vector_name)[0]\n",
        "        if len(idx) >= 1:\n",
        "            vector = self.item_mem[0][:, idx]\n",
        "        else:\n",
        "            print('No vector for name {} found!'.format(vector_name))\n",
        "            vector = None\n",
        "\n",
        "        return vector\n",
        "\n",
        "    def frac_binding(self, vector, k):\n",
        "        return self.fractional_binding(self.vsa, vector, k)\n",
        "\n",
        "    def convert(self, vector_array):\n",
        "        return self.convert_vectors(self.vsa, vector_array, self.density)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def rnd_name(size=(8,1)):\n",
        "      # Convert the list of strings to a NumPy array\n",
        "      strings = [generate_random_string(size[0]) for _ in range(size[1])]\n",
        "      array_of_strings = np.array(strings, dtype=np.dtype('U8'))\n",
        "      return array_of_strings\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_vectors(vsa, dim, num, density):\n",
        "        if vsa == 'MAP_C':\n",
        "            vectors = np.random.choice([-1, 1], size=(dim, num))\n",
        "        elif vsa == 'MAP_B':\n",
        "            vectors = np.random.choice([0, 1], size=(dim, num), p=[1 - density, density])\n",
        "        elif vsa == 'MAP_I':\n",
        "            vectors = np.eye(dim)[:, :num]\n",
        "        elif vsa == 'BSC':\n",
        "            vectors = np.random.choice([-1, 1], size=(dim, num))\n",
        "        elif vsa == 'BSDC':\n",
        "            vectors = np.random.choice([-1, 1], size=(dim, num))\n",
        "        elif vsa == 'BSDC_SHIFT':\n",
        "            vectors = np.random.choice([-1, 1], size=(dim, num))\n",
        "        elif vsa == 'HRR':\n",
        "            vectors = np.random.choice([-1, 1], size=(dim, num))\n",
        "        elif vsa == 'HRR_VTB':\n",
        "            vectors = np.random.choice([-1, 1], size=(dim, num))\n",
        "        elif vsa == 'FHRR':\n",
        "            vectors = np.random.choice([-1, 1], size=(dim, num))\n",
        "        elif vsa == 'BSDC_SEG':\n",
        "            vectors = np.random.choice([-1, 1], size=(dim, num))\n",
        "        elif vsa == 'MBAT':\n",
        "            vectors = np.random.choice([-1, 1], size=(dim, num))\n",
        "        else:\n",
        "            vectors = np.random.choice([-1, 1], size=(dim, num))\n",
        "\n",
        "        return vectors\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_sim(vsa, vectors_1, vectors_2):\n",
        "        # first transpose the arrays\n",
        "        vectors_1 = vectors_1.T\n",
        "        vectors_2 = vectors_2.T\n",
        "        sim_matrix = np.zeros((vectors_1.shape[0], vectors_2.shape[0]))\n",
        "        np.warnings.filterwarnings('ignore')\n",
        "        if vsa in ['MAP_B', 'MAP_C', 'HRR', 'HRR_VTB', 'NONE', 'MAP_I', 'MBAT', 'Proj', 'FHRR_cos']:\n",
        "            # cosine similarity\n",
        "            sim_matrix = (vectors_1 / np.sqrt(np.sum(vectors_1**2, axis=1, keepdims=True))) @ (vectors_2 / np.sqrt(np.sum(vectors_2**2, axis=1, keepdims=True))).T\n",
        "        elif vsa == 'BSC':\n",
        "            # hamming distance\n",
        "            sim_matrix = 1 - np.array([[hamming(vec1, vec2) for vec2 in vectors_2] for vec1 in vectors_1])\n",
        "        elif vsa in ['BSDC', 'BSDC_SHIFT', 'BSDC_25', 'BSDC_SEG', 'BSDC_THIN']:\n",
        "            # overlap\n",
        "            vectors_1 = vectors_1 > 0\n",
        "            vectors_2 = vectors_2 > 0\n",
        "            sim_matrix = np.dot(vectors_1,vectors_2.T)\n",
        "        elif vsa in ['FHRR_fft', 'FHRR']:\n",
        "            # average of cosine of distance\n",
        "            # convert to complex values\n",
        "            sim_matrix = np.real(np.exp(vectors_1*1j) @ np.exp(vectors_2*1j).T) / vectors_1.shape[1]\n",
        "        else:\n",
        "            print('Representation is not defined!')\n",
        "        np.warnings.filterwarnings('default')\n",
        "        return sim_matrix\n",
        "\n",
        "    @staticmethod\n",
        "    def bind_vectors(vsa, vectors_1, vectors_2, density):\n",
        "        default_density = 1/np.sqrt(vectors_1.shape[0])\n",
        "\n",
        "        bound_vectors = None\n",
        "\n",
        "        if vsa in ['MAP_B', 'MAP_C', 'MAP_I']:\n",
        "            bound_vectors = vectors_1 * vectors_2\n",
        "        elif vsa == 'BSC':\n",
        "            bound_vectors = np.double(np.add(vectors_1, vectors_2) == 1)\n",
        "        elif vsa == 'BSDC':\n",
        "            values_disj = np.double(np.add(vectors_1, vectors_2))\n",
        "            bound_vectors = cdt(values_disj, 50, 1/np.sqrt(vectors_1.shape[0]))\n",
        "        elif vsa == 'BSDC_SHIFT':\n",
        "            idx = np.arange(1, vectors_1.shape[0] + 1) @ vectors_1\n",
        "            # shift each column with a specific index number\n",
        "            bound_vectors = np.zeros_like(vectors_1)\n",
        "            for i in range(vectors_1.shape[1]):\n",
        "                bound_vectors[:, i] = np.roll(vectors_2[:, i], int(idx[i]))\n",
        "        elif vsa == 'HRR':\n",
        "            ccirc = np.fft.ifft(np.fft.fft(vectors_1, vectors_1.shape[0], axis=0) * np.fft.fft(vectors_2, vectors_2.shape[0], axis=0), axis=0)\n",
        "            bound_vectors = ccirc\n",
        "        elif vsa == 'FHRR':\n",
        "            bound_vectors = np.mod(vectors_1 + vectors_2 + np.pi, 2 * np.pi) - np.pi\n",
        "        elif vsa == 'BSDC_SEG':\n",
        "\n",
        "            # Sparse vectors with segments\n",
        "            dim = vectors_1.shape[0]\n",
        "            num_segments = int(np.floor(dim * density))\n",
        "            size_segments = int(np.floor(dim / num_segments))\n",
        "            num_vecs = vectors_1.shape[1]\n",
        "\n",
        "            role = vectors_1[:num_segments * size_segments, :]\n",
        "            filler = vectors_2[:num_segments * size_segments, :]\n",
        "\n",
        "            # First part of the vector\n",
        "            role_segments = role.reshape((size_segments, num_segments, num_vecs), order='F')\n",
        "            filler_segments = filler.reshape((size_segments, num_segments, num_vecs), order='F')\n",
        "\n",
        "            role_idx = np.flatnonzero(role_segments)\n",
        "            filler_idx = np.flatnonzero(filler_segments)\n",
        "\n",
        "            role_rows, _, _ = np.unravel_index(role_idx, role_segments.shape)\n",
        "            filler_rows, filler_cols, filler_tables = np.unravel_index(filler_idx, filler_segments.shape)\n",
        "\n",
        "            result_rows = np.mod(role_rows[filler_cols * filler_tables] + filler_rows - 1, size_segments) + 1\n",
        "\n",
        "            bound_vectors = np.zeros_like(role_segments)\n",
        "            idx = np.unravel_index(result_rows, role_segments.shape)\n",
        "            bound_vectors[idx] = 1\n",
        "            bound_vectors = bound_vectors.reshape((size_segments * num_segments, num_vecs), order='F')\n",
        "\n",
        "            bound_vectors_part2 = np.zeros_like(bound_vectors)\n",
        "            if num_segments * size_segments != dim:\n",
        "                filler = vectors_2[num_segments * size_segments:, :]\n",
        "                bound_vectors_part2[:filler.shape[0], :] = filler\n",
        "\n",
        "            bound_vectors = np.concatenate([bound_vectors, bound_vectors_part2], axis=0)\n",
        "        return bound_vectors\n",
        "\n",
        "    @staticmethod\n",
        "    def unbind_vectors(vsa, vectors_1, vectors_2, density):\n",
        "        if vsa in ['MAP_B', 'MAP_C', 'MAP_I']:\n",
        "        # elementwise multiplication\n",
        "            unbound_vectors = vectors_1 * vectors_2\n",
        "        elif vsa == 'BSC':\n",
        "            # efficient xor implementation for multi inputs\n",
        "            unbound_vectors = np.double(np.add(vectors_1, vectors_2) == 1)\n",
        "        elif vsa == 'BSDC':\n",
        "            # find the most similar item in item_mem\n",
        "            print('There is no specific unbind operator for the selected VSA - use the finding of the most similar vectors in item memory instead!')\n",
        "        elif vsa == 'BSDC_SHIFT':\n",
        "            # calculate the shift number (sum of all ones-index)\n",
        "            idx = np.arange(1, vectors_1.shape[0]+1).dot(vectors_1)\n",
        "            # shift each column with specific index number\n",
        "            unbound_vectors = np.zeros(vectors_1.shape)\n",
        "            for i in range(idx.size):\n",
        "                unbound_vectors[:, i] = np.roll(vectors_2[:, i], -int(idx[i]))\n",
        "        elif vsa == 'HRR':\n",
        "            # involution as approximate inverse\n",
        "            inverse = np.vstack((vectors_1[0, :], np.flip(vectors_1[1:, :], axis=0)))\n",
        "            unbound_vectors = np.fft.ifft(np.fft.fft(inverse, vectors_1.shape[0], axis=0) * np.fft.fft(vectors_2, vectors_2.shape[0], axis=0), axis=0)\n",
        "        elif vsa == 'FHRR':\n",
        "            # complex multiplication with negative 'role' vector\n",
        "            unbound_vectors = np.arctan2(np.sin(vectors_2 - vectors_1), np.cos(vectors_2 - vectors_1))\n",
        "        elif vsa == 'BSDC_SEG':\n",
        "            # Sparse vectors with segments\n",
        "            dim = vectors_1.shape[0]\n",
        "            num_segments = int(np.floor(dim * density))\n",
        "            num_vecs = vectors_1.shape[1]\n",
        "            size_segments = int(np.floor(dim / num_segments))\n",
        "            role = vectors_1[:num_segments * size_segments, :]\n",
        "            filler = vectors_2[:num_segments * size_segments, :]\n",
        "\n",
        "            # First part of the vector\n",
        "            role_segments = np.reshape(role, (size_segments, num_segments, num_vecs))\n",
        "            filler_segments = np.reshape(filler, (size_segments, num_segments, num_vecs))\n",
        "\n",
        "            # Initialize unbound_vectors with zeros\n",
        "            unbound_vectors = np.zeros(role_segments.shape)\n",
        "\n",
        "            # Loop through indices\n",
        "            for filler_table in range(num_segments):\n",
        "                for filler_col in range(num_vecs):\n",
        "                    for role_row in range(size_segments):\n",
        "                        # Calculate result_rows for each index\n",
        "                        result_rows = np.mod(filler_segments[:, filler_table, filler_col] - role_row - 1, size_segments) + 1\n",
        "                        result_rows = result_rows.astype(int)\n",
        "                        # Convert indices to flat indices\n",
        "                        idx = np.ravel_multi_index((result_rows, filler_col, filler_table), role_segments.shape)\n",
        "\n",
        "                        # Update unbound_vectors at the calculated indices\n",
        "                        unbound_vectors.flat[idx] = 1\n",
        "\n",
        "            # Reshape unbound_vectors\n",
        "            unbound_vectors = np.reshape(unbound_vectors, (size_segments * num_segments, num_vecs))\n",
        "\n",
        "            # If there is a remaining part\n",
        "            unbound_vectors_part2 = np.empty((0, num_vecs))\n",
        "            if num_segments * size_segments != dim:\n",
        "                filler = vectors_2[num_segments * size_segments:, :]\n",
        "                unbound_vectors_part2 = filler\n",
        "\n",
        "            # Stack unbound_vectors and unbound_vectors_part2 vertically\n",
        "            unbound_vectors = np.vstack((unbound_vectors, unbound_vectors_part2))\n",
        "        return unbound_vectors\n",
        "\n",
        "    @staticmethod\n",
        "    def bundle_vectors(vsa, vectors_1, vectors_2, normalize=None, density=None, max_density=None):\n",
        "        if normalize is None:\n",
        "            normalize = False\n",
        "\n",
        "        if density is None:\n",
        "            density = 0.5\n",
        "\n",
        "        if max_density is None:\n",
        "            max_density = 1\n",
        "\n",
        "        if vsa == 'MAP_C':\n",
        "            bundled_vectors = vectors_1 + vectors_2\n",
        "        elif vsa == 'MAP_B':\n",
        "            bundled_vectors = vectors_1 + vectors_2\n",
        "        elif vsa == 'MAP_I':\n",
        "            bundled_vectors = vectors_1 + vectors_2\n",
        "        elif vsa == 'BSC':\n",
        "            bundled_vectors = vectors_1 * vectors_2\n",
        "        elif vsa == 'BSDC':\n",
        "            bundled_vectors = vectors_1 * vectors_2\n",
        "        elif vsa == 'BSDC_SHIFT':\n",
        "            bundled_vectors = vectors_1 * vectors_2\n",
        "        elif vsa == 'HRR':\n",
        "            bundled_vectors = vectors_1 + vectors_2\n",
        "        elif vsa == 'HRR_VTB':\n",
        "            bundled_vectors = vectors_1 + vectors_2\n",
        "        elif vsa == 'FHRR':\n",
        "            bundled_vectors = vectors_1 + vectors_2\n",
        "        elif vsa == 'BSDC_SEG':\n",
        "            bundled_vectors = vectors_1 * vectors_2\n",
        "        elif vsa == 'MBAT':\n",
        "            bundled_vectors = vectors_1 + vectors_2\n",
        "        else:\n",
        "            bundled_vectors = vectors_1 + vectors_2\n",
        "\n",
        "        if normalize:\n",
        "            bundled_vectors = bundled_vectors / np.sqrt(np.sum(bundled_vectors**2, axis=0))\n",
        "\n",
        "        if density < max_density:\n",
        "            bundled_vectors = bundled_vectors * (density / max_density)\n",
        "\n",
        "        return bundled_vectors\n",
        "\n",
        "    @staticmethod\n",
        "    def fractional_binding(vsa, vector, k):\n",
        "        if vsa == 'MAP_C':\n",
        "            v = vector\n",
        "        elif vsa == 'MAP_B':\n",
        "            v = vector\n",
        "        elif vsa == 'MAP_I':\n",
        "            v = vector\n",
        "        elif vsa == 'BSC':\n",
        "            v = vector\n",
        "        elif vsa == 'BSDC':\n",
        "            v = vector\n",
        "        elif vsa == 'BSDC_SHIFT':\n",
        "            v = vector\n",
        "        elif vsa == 'HRR':\n",
        "            v = vector\n",
        "        elif vsa == 'HRR_VTB':\n",
        "            v = vector\n",
        "        elif vsa == 'FHRR':\n",
        "            v = vector\n",
        "        elif vsa == 'BSDC_SEG':\n",
        "            v = vector\n",
        "        elif vsa == 'MBAT':\n",
        "            v = vector\n",
        "        else:\n",
        "            v = vector\n",
        "\n",
        "        return v\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_vectors(vsa, vector_array, density):\n",
        "        if vsa == 'MAP_C':\n",
        "            converted_vectors = vector_array\n",
        "        elif vsa == 'MAP_B':\n",
        "            converted_vectors = vector_array\n",
        "        elif vsa == 'MAP_I':\n",
        "            converted_vectors = vector_array\n",
        "        elif vsa == 'BSC':\n",
        "            converted_vectors = vector_array\n",
        "        elif vsa == 'BSDC':\n",
        "            converted_vectors = vector_array\n",
        "        elif vsa == 'BSDC_SHIFT':\n",
        "            converted_vectors = vector_array\n",
        "        elif vsa == 'HRR':\n",
        "            converted_vectors = vector_array\n",
        "        elif vsa == 'HRR_VTB':\n",
        "            converted_vectors = vector_array\n",
        "        elif vsa == 'FHRR':\n",
        "            converted_vectors = vector_array\n",
        "        elif vsa == 'BSDC_SEG':\n",
        "            converted_vectors = vector_array\n",
        "        elif vsa == 'MBAT':\n",
        "            converted_vectors = vector_array\n",
        "        else:\n",
        "            converted_vectors = vector_array\n",
        "\n",
        "        return converted_vectors"
      ],
      "metadata": {
        "id": "9f-3GYrHmQ3o"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**demo_cpu:**\n",
        "\n",
        "Demonstrates the usage of the Vector Symbolic Architecture (VSA) in Python for various VSA types. It loads images from a directory, converts them to vectors, and performs VSA operations like bundling, binding/unbinding, and vector retrieval. The code iterates through different VSA types, including MAP, BSC, BSDC, HRR, FHRR, and more. It measures the elapsed time for each operation, prints similarity values where applicable, and demonstrates finding vectors using the item memory and handling noise vectors."
      ],
      "metadata": {
        "id": "F8bAeXcrjVxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "# Suppress warnings\n",
        "sys.stderr = open(os.devnull, 'w')\n",
        "sys.stderr = sys.__stderr__\n",
        "\n",
        "# create the object of a specific VSA type\n",
        "vsa_types = ['MAP_C', 'MAP_B', 'MAP_I', 'BSC', 'BSDC', 'BSDC_SHIFT', 'HRR', 'FHRR']\n",
        "for type_idx in range(len(vsa_types)):\n",
        "    type = vsa_types[type_idx]\n",
        "    VSA = vsa_env(type, 1024)\n",
        "\n",
        "    # Load images from a directory in Google Drive\n",
        "    imageDir = '/content/drive/MyDrive/GardensPointWalking/night_right'\n",
        "    imageFiles = [file for file in os.listdir(imageDir) if file.endswith('.jpg')]\n",
        "\n",
        "\n",
        "    # Initialize the combined vector\n",
        "    combinedVector = []\n",
        "\n",
        "    # Iterate through each image and convert it to a vector\n",
        "    for i in range(len(imageFiles)//2):\n",
        "        currentFileName = imageFiles[i]\n",
        "        currentImagePath = os.path.join(imageDir, currentFileName)\n",
        "\n",
        "        # Read the image\n",
        "        img = Image.open(currentImagePath)\n",
        "        squareSize = 256\n",
        "        img = img.resize((squareSize, squareSize)).convert('L')\n",
        "        imgVector = np.array(img).reshape(-1, 1)\n",
        "        combinedVector.append(imgVector)\n",
        "    combinedVector = np.squeeze(np.array(combinedVector))\n",
        "    combinedVector = np.reshape(combinedVector, (combinedVector.shape[1], combinedVector.shape[0]))\n",
        "    VSA.add_vector(combinedVector)\n",
        "    combinedVector1 = []\n",
        "\n",
        "    # Iterate through each image and convert it to a vector\n",
        "    for i in range(len(imageFiles)//2, len(imageFiles)):\n",
        "        currentFileName = imageFiles[i]\n",
        "        currentImagePath = os.path.join(imageDir, currentFileName)\n",
        "\n",
        "        # Read the image\n",
        "        img = Image.open(currentImagePath)\n",
        "        squareSize = 256\n",
        "        img = img.resize((squareSize, squareSize)).convert('L')\n",
        "        imgVector = np.array(img).reshape(-1, 1)\n",
        "        combinedVector1.append(imgVector)\n",
        "    combinedVector1 = np.squeeze(np.array(combinedVector1))\n",
        "    combinedVector1 = np.reshape(combinedVector1, (combinedVector1.shape[1], combinedVector1.shape[0]))\n",
        "    rows, cols = combinedVector.shape\n",
        "    rows1, cols1 = combinedVector1.shape\n",
        "\n",
        "    if cols != cols1:\n",
        "        # Remove the last index of the longer vector to make them equal\n",
        "        minLength = min(cols, cols1)\n",
        "        combinedVector1 = combinedVector1[:, :minLength]\n",
        "\n",
        "    ## 1. bundling\n",
        "\n",
        "    print('Bundling vectors for VSA type: ' + type)\n",
        "    start_time = time.time()\n",
        "    if type != 'FHRR':\n",
        "        bundle = VSA.bundle(combinedVector, combinedVector1)  # Use the vectors directly\n",
        "    end_time = time.time()\n",
        "    print(f'Elapsed time: {end_time-start_time:.5f} seconds')\n",
        "\n",
        "    ## 2. binding / unbinding\n",
        "\n",
        "    if type == 'BSDC':\n",
        "        print('Binding vectors for VSA type: ' + type)\n",
        "        start_time = time.time()\n",
        "        v_array_1 = VSA.add_vector(combinedVector,add_item=1)\n",
        "        v_array_2 = VSA.add_vector(combinedVector1,add_item=1)\n",
        "        bound_v = VSA.bind(v_array_1.astype(float), v_array_2.astype(float))  # Use the vectors directly\n",
        "        end_time = time.time()\n",
        "        print(f'Elapsed time: {end_time-start_time:.5f} seconds')\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Use similarity search for BSDC\n",
        "        v_clean, name, s = VSA.find_k_nearest(np.array(bound_v), 1)\n",
        "        sim_v1 = s\n",
        "    else:\n",
        "        print('Binding vectors for VSA type: ' + type)\n",
        "        start_time = time.time()\n",
        "        v_array_1 = VSA.add_vector(combinedVector)\n",
        "        v_array_2 = VSA.add_vector(combinedVector1)\n",
        "        bound_v = VSA.bind(v_array_1.astype(float), v_array_2.astype(float))  # Use the vectors directly\n",
        "        end_time = time.time()\n",
        "        print(f'Elapsed time: {end_time-start_time:.5f} seconds')\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Regular unbinding operation for other VSA types\n",
        "        r = VSA.unbind(v_array_1.astype(float), bound_v.astype(float))\n",
        "        sim_v1 = VSA.sim(r.astype(float), v_array_1.astype(float))\n",
        "        sim_v2 = VSA.sim(r.astype(float), v_array_2.astype(float))\n",
        "    end_time = time.time()\n",
        "    print('------- unbinding:')\n",
        "    print(f'Elapsed time: {end_time-start_time:.5f} seconds')\n",
        "\n",
        "    ## 3. use the item memory to find vectors\n",
        "\n",
        "    print('Finding k vectors for VSA type: ' + type)\n",
        "\n",
        "    # fill the item memory with random vectors\n",
        "    VSA = vsa_env(type, 65536)\n",
        "    v_array_1 = VSA.add_vector(combinedVector[:,1][:, np.newaxis].astype(float))\n",
        "    v = VSA.add_vector(add_item=1)\n",
        "    v_clean, name, s = VSA.find_k_nearest(v.astype(float), 1)\n",
        "\n",
        "    # Convert similarity to percentage for BSDC types\n",
        "    if type == 'BSDC' or type == 'BSDC_SHIFT' or type == 'BSDC_SEG':\n",
        "        # Extract the first element from the array if s is an array\n",
        "        similarity_value = s[0][0] if isinstance(s, np.ndarray) else s\n",
        "        # Convert raw similarity scores to decimal format for BSDC types\n",
        "        similarity_decimal = similarity_value / 1024\n",
        "        print(f'Found probe vector with similarity of {similarity_decimal:.5f}')\n",
        "    else:\n",
        "        # Extract the first element from the array if s is an array\n",
        "        similarity_value = s[0][0] if isinstance(s, np.ndarray) else s\n",
        "        print(f'Found probe vector with similarity of {similarity_value:.5f}')\n",
        "\n",
        "    # bundle the probe with noise vector\n",
        "    noise = VSA.add_vector()\n",
        "    bundle = VSA.bundle(v, noise)\n",
        "    v_clean, name, s = VSA.find_k_nearest(bundle, 1)\n",
        "\n",
        "    # Convert similarity to decimal format for BSDC types\n",
        "    if type == 'BSDC' or type == 'BSDC_SHIFT' or type == 'BSDC_SEG':\n",
        "        # Extract the first element from the array if s is an array\n",
        "        similarity_value = s[0][0] if isinstance(s, np.ndarray) else s\n",
        "        similarity_decimal = similarity_value / 1024\n",
        "        print(f'Found noisy vector probe with similarity of {similarity_decimal:.5f}')\n",
        "    else:\n",
        "        # Extract the first element from the array if s is an array\n",
        "        similarity_value = s[0][0] if isinstance(s, np.ndarray) else s\n",
        "        print(f'Found noisy vector with similarity of {similarity_value:.5f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5zff8JBjVp-",
        "outputId": "c5f6ed88-e2c3-480c-db91-663b296cb742"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bundling vectors for VSA type: MAP_C\n",
            "Elapsed time: 0.02827 seconds\n",
            "Binding vectors for VSA type: MAP_C\n",
            "Elapsed time: 0.07503 seconds\n",
            "------- unbinding:\n",
            "Elapsed time: 0.44154 seconds\n",
            "Finding k vectors for VSA type: MAP_C\n",
            "Found probe vector with similarity of 1.00000\n",
            "Found noisy vector with similarity of 0.70669\n",
            "Bundling vectors for VSA type: MAP_B\n",
            "Elapsed time: 0.02131 seconds\n",
            "Binding vectors for VSA type: MAP_B\n",
            "Elapsed time: 0.05724 seconds\n",
            "------- unbinding:\n",
            "Elapsed time: 0.44021 seconds\n",
            "Finding k vectors for VSA type: MAP_B\n",
            "Found probe vector with similarity of 1.00000\n",
            "Found noisy vector with similarity of 0.86581\n",
            "Bundling vectors for VSA type: MAP_I\n",
            "Elapsed time: 0.02170 seconds\n",
            "Binding vectors for VSA type: MAP_I\n",
            "Elapsed time: 0.06126 seconds\n",
            "------- unbinding:\n",
            "Elapsed time: 0.41099 seconds\n",
            "Finding k vectors for VSA type: MAP_I\n",
            "Found probe vector with similarity of 1.00000\n",
            "Found noisy vector with similarity of 1.00000\n",
            "Bundling vectors for VSA type: BSC\n",
            "Elapsed time: 0.02024 seconds\n",
            "Binding vectors for VSA type: BSC\n",
            "Elapsed time: 0.08384 seconds\n",
            "------- unbinding:\n",
            "Elapsed time: 11.58225 seconds\n",
            "Finding k vectors for VSA type: BSC\n",
            "Found probe vector with similarity of 1.00000\n",
            "Found noisy vector with similarity of 0.00000\n",
            "Bundling vectors for VSA type: BSDC\n",
            "Elapsed time: 0.02131 seconds\n",
            "Binding vectors for VSA type: BSDC\n",
            "Elapsed time: 0.11929 seconds\n",
            "------- unbinding:\n",
            "Elapsed time: 2.95871 seconds\n",
            "Finding k vectors for VSA type: BSDC\n",
            "Found probe vector with similarity of 0.00098\n",
            "Found noisy vector probe with similarity of 0.00098\n",
            "Bundling vectors for VSA type: BSDC_SHIFT\n",
            "Elapsed time: 0.02204 seconds\n",
            "Binding vectors for VSA type: BSDC_SHIFT\n",
            "Elapsed time: 0.13041 seconds\n",
            "------- unbinding:\n",
            "Elapsed time: 0.25131 seconds\n",
            "Finding k vectors for VSA type: BSDC_SHIFT\n",
            "Found probe vector with similarity of 0.00098\n",
            "Found noisy vector probe with similarity of 0.00098\n",
            "Bundling vectors for VSA type: HRR\n",
            "Elapsed time: 0.02166 seconds\n",
            "Binding vectors for VSA type: HRR\n",
            "Elapsed time: 0.62457 seconds\n",
            "------- unbinding:\n",
            "Elapsed time: 1.02816 seconds\n",
            "Finding k vectors for VSA type: HRR\n",
            "Found probe vector with similarity of 1.00000\n",
            "Found noisy vector with similarity of 0.70519\n",
            "Bundling vectors for VSA type: FHRR\n",
            "Elapsed time: 0.00000 seconds\n",
            "Binding vectors for VSA type: FHRR\n",
            "Elapsed time: 0.31994 seconds\n",
            "------- unbinding:\n",
            "Elapsed time: 2.29390 seconds\n",
            "Finding k vectors for VSA type: FHRR\n",
            "Found probe vector with similarity of -0.41615\n",
            "Found noisy vector with similarity of 0.06183\n"
          ]
        }
      ]
    }
  ]
}